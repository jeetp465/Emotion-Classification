{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['affection', 'love', 'positive'], ['cheerfullness', 'joy', 'positive'], ['confusion', 'confusion', 'negative'], ['contentment', 'joy', 'positive'], ['disappointment', 'sadness', 'negative'], ['disgust', 'anger', 'negative'], ['enthrallment', 'joy', 'positive'], ['envy', 'anger', 'negative'], ['exasperation', 'anger', 'negative'], ['gratitude', 'love', 'positive'], ['horror', 'fear', 'negative'], ['irritabilty', 'anger', 'negative'], ['lust', 'love', 'positive'], ['neglect', 'sadness', 'negative'], ['nervousness', 'fear', 'negative'], ['optimism', 'joy', 'positive'], ['pride', 'joy', 'positive'], ['rage', 'anger', 'negative'], ['relief', 'joy', 'positive'], ['sadness', 'sadness', 'negative'], ['shame', 'sadness', 'negative'], ['suffering', 'sadness', 'negative'], ['surprise', 'surprise', 'positive'], ['sympathy', 'sadness', 'negative'], ['zest', 'joy', 'positive']]\n"
     ]
    }
   ],
   "source": [
    "path = '/home/jeet/WEBEmo/category.txt'\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "content = [elem.strip('\\n').split(',') for elem in content]   \n",
    "\n",
    "for elem in content:\n",
    "    if elem[2] == '+':\n",
    "        elem[2] = 'positive'\n",
    "    else:\n",
    "        elem[2] = 'negative'\n",
    "        \n",
    "print (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': [0, 1, 3, 6, 9, 12, 15, 16, 18, 22, 24], 'negative': [2, 4, 5, 7, 8, 10, 11, 13, 14, 17, 19, 20, 21, 23]}\n",
      "{'love': [0, 9, 12], 'joy': [1, 3, 6, 15, 16, 18, 24], 'confusion': [2], 'sadness': [4, 13, 19, 20, 21, 23], 'anger': [5, 7, 8, 11, 17], 'fear': [10, 14], 'surprise': [22]}\n"
     ]
    }
   ],
   "source": [
    "level1 = dict()\n",
    "level2 = dict()\n",
    "\n",
    "for i, elem in enumerate(content):\n",
    "    if elem[2] not in level1.keys():\n",
    "        level1[elem[2]] = []\n",
    "    level1[elem[2]].append(i)\n",
    "    \n",
    "    if elem[1] not in level2.keys():\n",
    "        level2[elem[1]] = []\n",
    "        \n",
    "    level2[elem[1]].append(i)\n",
    "    \n",
    "print (level1)\n",
    "print (level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the label of the folder \n",
    "def get_key(label_dict, val):\n",
    "    for key, val_list in label_dict.items():\n",
    "        if val in val_list:\n",
    "            return key\n",
    "        \n",
    "# Function to make the dataset. Returns list of tuple (path, label) for the image\n",
    "def make_dataset(root_dir, label_dict, class_to_idx):\n",
    "    images = []\n",
    "    for target in sorted(os.listdir(root_dir)):\n",
    "        d = os.path.join(root_dir, target)\n",
    "        \n",
    "        try :\n",
    "            int(target)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        label = get_key(label_dict, int(target))\n",
    "        label = class_to_idx[label]\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "                item = (path, label)\n",
    "                images.append(item)\n",
    "\n",
    "    return images\n",
    "\n",
    "# Helper function to load the images given the path of the image\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "    \n",
    "# Attribute of the class Level1ImageDataSet    \n",
    "def find_classes(root_dir, label_dict):\n",
    "    classes = []\n",
    "    \n",
    "    for label_dir in sorted(os.listdir(root_dir)):\n",
    "        try:\n",
    "            int(label_dir)\n",
    "            classes.append(get_key(label_dict, int(label_dir)))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    classes = list(set(classes))\n",
    "    \n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, label_dict, transform=None):\n",
    "        super(CustomImageDataset, self).__init__()\n",
    "        \n",
    "        classes, class_to_idx = find_classes(root_dir, label_dict)\n",
    "        samples = make_dataset(root_dir, label_dict, class_to_idx)\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_dict = label_dict\n",
    "        \n",
    "        self.samples = samples\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.samples))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        path, label = self.samples[index]\n",
    "        sample = pil_loader(path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n",
    "    \n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root_dir)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/jeet/WEBEmo/'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dset_l1 = {x: CustomImageDataset(os.path.join(data_dir, x), level1, data_transforms[x]) for x in ['train','test']}\n",
    "dset_l2 = {x: CustomImageDataset(os.path.join(data_dir, x), level2, data_transforms[x]) for x in ['train','test']}\n",
    "\n",
    "dset_loader_l1 = {x: DataLoader(dset_l1[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=16) for x in ['train', 'test']}\n",
    "dset_loader_l2 = {x: DataLoader(dset_l2[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=16) for x in ['train', 'test']}\n",
    "\n",
    "dset_sizes = {x: len(dset_l1[x]) for x in ['train', 'test']}\n",
    "dset_sizes = {x: len(dset_l2[x]) for x in ['train', 'test']}\n",
    "\n",
    "dset_classes_l1 = dset_l1['train'].classes\n",
    "dset_classes_l2 = dset_l2['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, scheduler, num_epochs = 10):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        \n",
    "        best_acc = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(dataloader['train']):\n",
    "            \n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_acc += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                try:\n",
    "                    avg = train_acc.double() / (i * BATCH_SIZE)\n",
    "                    print (\"Average correctly classified images till {} batches: {}\".format(i, avg))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "        epoch_loss = train_loss / (len(dataloader['train']) * BATCH_SIZE)\n",
    "        epoch_acc = train_acc.double() / (len(dataloader['train']) * BATCH_SIZE)\n",
    "        \n",
    "        print (\"Epoch: {}, Epoch_Accuracy: {:.2f}, Epoch_loss: {:.4f}\".format(epoch, epoch_acc, epoch_loss))\n",
    "        \n",
    "        # Evaluate on the test set\n",
    "        test_acc = test(model, dataloader)\n",
    "\n",
    "#       Save the model weights if the test acc is greater than our current best\n",
    "        if test_acc > best_acc:\n",
    "            best_model_wt = model.state_dict()\n",
    "            print(\"Chekcpoint updated\")\n",
    "            best_acc = test_acc\n",
    "\n",
    "        # Print the metrics\n",
    "        print(\"Test Accuracy: {:.4f}, Best Accuracy: {:.4f}\".format(test_acc, best_acc))\n",
    "        \n",
    "#   Save the best model weights\n",
    "    torch.save(best_model_wt, \"Resnet50_Transfer_Learning.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(dataloader['test']):\n",
    "\n",
    "        images = Variable(images.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        # Predict classes using images from the test set\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        \n",
    "        test_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "    # Compute the average acc and loss over all test images\n",
    "    test_acc = test_acc.double() / (len(dataloader['test']) * BATCH_SIZE)\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = models.resnet50(pretrained=True)\n",
    "\n",
    "for params in model_conv.parameters():\n",
    "    params.requires_grad=False\n",
    "    \n",
    "num_features = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Sequential(nn.Linear(num_features, 256),\n",
    "                              nn.BatchNorm1d(256),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(p = 0.5),\n",
    "                              nn.Linear(256, 50),\n",
    "                              nn.BatchNorm1d(50),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(p = 0.5),\n",
    "                              nn.Linear(50, 2))\n",
    "\n",
    "model_conv.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = optim.Adam(model_conv.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=256, out_features=50, bias=True)\n",
      "    (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5)\n",
      "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.59578125\n",
      "Average correctly classified images till 200 batches: 0.60875\n",
      "Average correctly classified images till 300 batches: 0.6170833333333334\n",
      "Average correctly classified images till 400 batches: 0.62375\n",
      "Average correctly classified images till 500 batches: 0.6281875\n",
      "Average correctly classified images till 600 batches: 0.6328645833333334\n",
      "Average correctly classified images till 700 batches: 0.634375\n",
      "Average correctly classified images till 800 batches: 0.6361328125\n",
      "Average correctly classified images till 900 batches: 0.6363368055555556\n",
      "Average correctly classified images till 1200 batches: 0.6394270833333334\n",
      "Average correctly classified images till 1300 batches: 0.6395192307692308\n",
      "Average correctly classified images till 1400 batches: 0.6411160714285714\n",
      "Average correctly classified images till 1500 batches: 0.6411979166666667\n",
      "Average correctly classified images till 1600 batches: 0.641962890625\n",
      "Average correctly classified images till 1700 batches: 0.6422886029411764\n",
      "Average correctly classified images till 1800 batches: 0.6430642361111111\n",
      "Average correctly classified images till 1900 batches: 0.643922697368421\n",
      "Average correctly classified images till 2000 batches: 0.64484375\n",
      "Average correctly classified images till 2100 batches: 0.6449702380952381\n",
      "Average correctly classified images till 2200 batches: 0.6457599431818182\n",
      "Average correctly classified images till 2300 batches: 0.6462567934782609\n",
      "Average correctly classified images till 2400 batches: 0.6467513020833334\n",
      "Average correctly classified images till 2500 batches: 0.64696875\n",
      "Average correctly classified images till 2600 batches: 0.6475180288461538\n",
      "Average correctly classified images till 2700 batches: 0.6482812499999999\n",
      "Average correctly classified images till 2800 batches: 0.6488839285714286\n",
      "Average correctly classified images till 2900 batches: 0.649040948275862\n",
      "Average correctly classified images till 3000 batches: 0.6492291666666666\n",
      "Average correctly classified images till 3100 batches: 0.6494254032258064\n",
      "Average correctly classified images till 3200 batches: 0.649697265625\n",
      "Average correctly classified images till 3300 batches: 0.6503125\n",
      "Epoch: 0, Epoch_Accuracy: 0.65, Epoch_loss: 0.6257\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6774, Best Accuracy: 0.6774\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.6765625000000001\n",
      "Average correctly classified images till 200 batches: 0.66625\n",
      "Average correctly classified images till 300 batches: 0.6637500000000001\n",
      "Average correctly classified images till 400 batches: 0.6639453125\n",
      "Average correctly classified images till 500 batches: 0.6638125\n",
      "Average correctly classified images till 600 batches: 0.6629427083333334\n",
      "Average correctly classified images till 700 batches: 0.66203125\n",
      "Average correctly classified images till 800 batches: 0.66158203125\n",
      "Average correctly classified images till 900 batches: 0.6614409722222222\n",
      "Average correctly classified images till 1000 batches: 0.6607968750000001\n",
      "Average correctly classified images till 1100 batches: 0.66109375\n",
      "Average correctly classified images till 1200 batches: 0.6607161458333334\n",
      "Average correctly classified images till 1300 batches: 0.6612259615384616\n",
      "Average correctly classified images till 1400 batches: 0.6604799107142857\n",
      "Average correctly classified images till 1500 batches: 0.6608229166666666\n",
      "Average correctly classified images till 1600 batches: 0.66166015625\n",
      "Average correctly classified images till 1700 batches: 0.6618198529411764\n",
      "Average correctly classified images till 1800 batches: 0.6624739583333333\n",
      "Average correctly classified images till 1900 batches: 0.6619901315789474\n",
      "Average correctly classified images till 2000 batches: 0.662015625\n",
      "Average correctly classified images till 2100 batches: 0.6618303571428571\n",
      "Average correctly classified images till 2200 batches: 0.6615198863636363\n",
      "Average correctly classified images till 2300 batches: 0.6614402173913043\n",
      "Average correctly classified images till 2400 batches: 0.6614583333333334\n",
      "Average correctly classified images till 2500 batches: 0.6614562500000001\n",
      "Average correctly classified images till 2600 batches: 0.6614603365384616\n",
      "Average correctly classified images till 2700 batches: 0.6614988425925925\n",
      "Average correctly classified images till 2800 batches: 0.6613113839285715\n",
      "Average correctly classified images till 2900 batches: 0.6610560344827586\n",
      "Average correctly classified images till 3000 batches: 0.6611197916666667\n",
      "Average correctly classified images till 3100 batches: 0.6609627016129033\n",
      "Average correctly classified images till 3200 batches: 0.660859375\n",
      "Average correctly classified images till 3300 batches: 0.6608333333333334\n",
      "Epoch: 1, Epoch_Accuracy: 0.66, Epoch_loss: 0.6162\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6832, Best Accuracy: 0.6832\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.66296875\n",
      "Average correctly classified images till 200 batches: 0.662421875\n",
      "Average correctly classified images till 300 batches: 0.6603645833333334\n",
      "Average correctly classified images till 400 batches: 0.6606640625\n",
      "Average correctly classified images till 500 batches: 0.66021875\n",
      "Average correctly classified images till 600 batches: 0.6598697916666667\n",
      "Average correctly classified images till 700 batches: 0.6596205357142857\n",
      "Average correctly classified images till 800 batches: 0.6596484375\n",
      "Average correctly classified images till 900 batches: 0.6600694444444445\n",
      "Average correctly classified images till 1000 batches: 0.6598906250000001\n",
      "Average correctly classified images till 1100 batches: 0.65953125\n",
      "Average correctly classified images till 1200 batches: 0.659375\n",
      "Average correctly classified images till 1300 batches: 0.6595072115384616\n",
      "Average correctly classified images till 1400 batches: 0.6601227678571429\n",
      "Average correctly classified images till 1500 batches: 0.6602812499999999\n",
      "Average correctly classified images till 1600 batches: 0.65994140625\n",
      "Average correctly classified images till 1700 batches: 0.6604136029411765\n",
      "Average correctly classified images till 1800 batches: 0.6605034722222223\n",
      "Average correctly classified images till 1900 batches: 0.6608305921052632\n",
      "Average correctly classified images till 2000 batches: 0.6604609375\n",
      "Average correctly classified images till 2100 batches: 0.6613839285714286\n",
      "Average correctly classified images till 2200 batches: 0.6615411931818181\n",
      "Average correctly classified images till 2300 batches: 0.6616779891304349\n",
      "Average correctly classified images till 2400 batches: 0.6616471354166668\n",
      "Average correctly classified images till 2500 batches: 0.6618875000000001\n",
      "Average correctly classified images till 2600 batches: 0.6619290865384615\n",
      "Average correctly classified images till 2700 batches: 0.661724537037037\n",
      "Average correctly classified images till 2800 batches: 0.6612667410714286\n",
      "Average correctly classified images till 2900 batches: 0.6612661637931034\n",
      "Average correctly classified images till 3000 batches: 0.661109375\n",
      "Average correctly classified images till 3100 batches: 0.6614012096774193\n",
      "Average correctly classified images till 3200 batches: 0.661640625\n",
      "Average correctly classified images till 3300 batches: 0.6617329545454546\n",
      "Epoch: 2, Epoch_Accuracy: 0.66, Epoch_loss: 0.6152\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6843, Best Accuracy: 0.6843\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.67484375\n",
      "Average correctly classified images till 200 batches: 0.66984375\n",
      "Average correctly classified images till 300 batches: 0.6705729166666667\n",
      "Average correctly classified images till 400 batches: 0.66625\n",
      "Average correctly classified images till 500 batches: 0.66503125\n",
      "Average correctly classified images till 600 batches: 0.6634895833333334\n",
      "Average correctly classified images till 700 batches: 0.6624330357142857\n",
      "Average correctly classified images till 800 batches: 0.66208984375\n",
      "Average correctly classified images till 900 batches: 0.6623611111111111\n",
      "Average correctly classified images till 1000 batches: 0.662625\n",
      "Average correctly classified images till 1100 batches: 0.6629403409090909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctly classified images till 1200 batches: 0.6632552083333334\n",
      "Average correctly classified images till 1300 batches: 0.6634495192307692\n",
      "Average correctly classified images till 1400 batches: 0.6630357142857143\n",
      "Average correctly classified images till 1500 batches: 0.66334375\n",
      "Average correctly classified images till 1600 batches: 0.66388671875\n",
      "Average correctly classified images till 1700 batches: 0.6642738970588234\n",
      "Average correctly classified images till 1800 batches: 0.6640104166666667\n",
      "Average correctly classified images till 1900 batches: 0.6635361842105263\n",
      "Average correctly classified images till 2000 batches: 0.6631328125\n",
      "Average correctly classified images till 2100 batches: 0.6635491071428572\n",
      "Average correctly classified images till 2200 batches: 0.6634872159090909\n",
      "Average correctly classified images till 2300 batches: 0.6636616847826087\n",
      "Average correctly classified images till 2400 batches: 0.6637044270833333\n",
      "Average correctly classified images till 2500 batches: 0.6633\n",
      "Average correctly classified images till 2600 batches: 0.6634975961538462\n",
      "Average correctly classified images till 2700 batches: 0.6630960648148148\n",
      "Average correctly classified images till 2800 batches: 0.6632477678571429\n",
      "Average correctly classified images till 2900 batches: 0.6630118534482758\n",
      "Average correctly classified images till 3000 batches: 0.6627604166666666\n",
      "Average correctly classified images till 3100 batches: 0.6629435483870968\n",
      "Average correctly classified images till 3200 batches: 0.66283203125\n",
      "Average correctly classified images till 3300 batches: 0.6626704545454546\n",
      "Epoch: 3, Epoch_Accuracy: 0.66, Epoch_loss: 0.6148\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6871, Best Accuracy: 0.6871\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.675\n",
      "Average correctly classified images till 200 batches: 0.670078125\n",
      "Average correctly classified images till 300 batches: 0.6644791666666667\n",
      "Average correctly classified images till 400 batches: 0.66515625\n",
      "Average correctly classified images till 500 batches: 0.66515625\n",
      "Average correctly classified images till 600 batches: 0.6664062500000001\n",
      "Average correctly classified images till 700 batches: 0.6650223214285714\n",
      "Average correctly classified images till 800 batches: 0.66537109375\n",
      "Average correctly classified images till 900 batches: 0.6652777777777777\n",
      "Average correctly classified images till 1000 batches: 0.664765625\n",
      "Average correctly classified images till 1100 batches: 0.6646022727272727\n",
      "Average correctly classified images till 1200 batches: 0.665625\n",
      "Average correctly classified images till 1300 batches: 0.666298076923077\n",
      "Average correctly classified images till 1400 batches: 0.6663950892857143\n",
      "Average correctly classified images till 1500 batches: 0.6666875\n",
      "Average correctly classified images till 1600 batches: 0.666484375\n",
      "Average correctly classified images till 1700 batches: 0.6658639705882352\n",
      "Average correctly classified images till 1800 batches: 0.6662152777777778\n",
      "Average correctly classified images till 1900 batches: 0.6657401315789474\n",
      "Average correctly classified images till 2000 batches: 0.6655546875\n",
      "Average correctly classified images till 2100 batches: 0.6658035714285714\n",
      "Average correctly classified images till 2200 batches: 0.6658877840909091\n",
      "Average correctly classified images till 2300 batches: 0.6655774456521739\n",
      "Average correctly classified images till 2400 batches: 0.6654361979166667\n",
      "Average correctly classified images till 2500 batches: 0.6651312500000001\n",
      "Average correctly classified images till 2600 batches: 0.6648617788461538\n",
      "Average correctly classified images till 2700 batches: 0.6647280092592592\n",
      "Average correctly classified images till 2800 batches: 0.6647823660714286\n",
      "Average correctly classified images till 2900 batches: 0.6647413793103448\n",
      "Average correctly classified images till 3000 batches: 0.6646302083333333\n",
      "Average correctly classified images till 3100 batches: 0.6649042338709678\n",
      "Average correctly classified images till 3200 batches: 0.6646240234375\n",
      "Average correctly classified images till 3300 batches: 0.664715909090909\n",
      "Epoch: 4, Epoch_Accuracy: 0.66, Epoch_loss: 0.6132\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6865, Best Accuracy: 0.6865\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.6721875\n",
      "Average correctly classified images till 200 batches: 0.66921875\n",
      "Average correctly classified images till 300 batches: 0.6685937500000001\n",
      "Average correctly classified images till 400 batches: 0.67015625\n",
      "Average correctly classified images till 500 batches: 0.6684375\n",
      "Average correctly classified images till 600 batches: 0.6668489583333334\n",
      "Average correctly classified images till 700 batches: 0.6672544642857143\n",
      "Average correctly classified images till 800 batches: 0.6680273437500001\n",
      "Average correctly classified images till 900 batches: 0.66796875\n",
      "Average correctly classified images till 1000 batches: 0.66728125\n",
      "Average correctly classified images till 1100 batches: 0.6673295454545455\n",
      "Average correctly classified images till 1200 batches: 0.6674609375\n",
      "Average correctly classified images till 1300 batches: 0.6675120192307692\n",
      "Average correctly classified images till 1400 batches: 0.6672544642857143\n",
      "Average correctly classified images till 1500 batches: 0.66671875\n",
      "Average correctly classified images till 1600 batches: 0.666630859375\n",
      "Average correctly classified images till 1700 batches: 0.66640625\n",
      "Average correctly classified images till 1800 batches: 0.666328125\n",
      "Average correctly classified images till 1900 batches: 0.6663157894736842\n",
      "Average correctly classified images till 2000 batches: 0.6664921875\n",
      "Average correctly classified images till 2100 batches: 0.6668080357142857\n",
      "Average correctly classified images till 2200 batches: 0.6666832386363636\n",
      "Average correctly classified images till 2300 batches: 0.6663858695652174\n",
      "Average correctly classified images till 2400 batches: 0.6662760416666668\n",
      "Average correctly classified images till 2500 batches: 0.66604375\n",
      "Average correctly classified images till 2600 batches: 0.6666706730769231\n",
      "Average correctly classified images till 2700 batches: 0.6668287037037036\n",
      "Average correctly classified images till 2800 batches: 0.6666852678571429\n",
      "Average correctly classified images till 2900 batches: 0.6666379310344827\n",
      "Average correctly classified images till 3000 batches: 0.6665364583333333\n",
      "Average correctly classified images till 3100 batches: 0.6662852822580645\n",
      "Average correctly classified images till 3200 batches: 0.6663037109375\n",
      "Average correctly classified images till 3300 batches: 0.6661126893939394\n",
      "Epoch: 5, Epoch_Accuracy: 0.67, Epoch_loss: 0.6120\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6883, Best Accuracy: 0.6883\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.6721875\n",
      "Average correctly classified images till 200 batches: 0.664296875\n",
      "Average correctly classified images till 300 batches: 0.6633854166666667\n",
      "Average correctly classified images till 400 batches: 0.6641796875\n",
      "Average correctly classified images till 500 batches: 0.663375\n",
      "Average correctly classified images till 600 batches: 0.6651822916666668\n",
      "Average correctly classified images till 700 batches: 0.6659151785714286\n",
      "Average correctly classified images till 800 batches: 0.66693359375\n",
      "Average correctly classified images till 900 batches: 0.6668576388888889\n",
      "Average correctly classified images till 1000 batches: 0.666984375\n",
      "Average correctly classified images till 1100 batches: 0.6665909090909091\n",
      "Average correctly classified images till 1200 batches: 0.6672265625\n",
      "Average correctly classified images till 1300 batches: 0.6665985576923077\n",
      "Average correctly classified images till 1400 batches: 0.6655691964285714\n",
      "Average correctly classified images till 1500 batches: 0.6660833333333334\n",
      "Average correctly classified images till 1600 batches: 0.665791015625\n",
      "Average correctly classified images till 1700 batches: 0.6658823529411764\n",
      "Average correctly classified images till 1800 batches: 0.6651215277777778\n",
      "Average correctly classified images till 1900 batches: 0.664876644736842\n",
      "Average correctly classified images till 2000 batches: 0.664765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctly classified images till 2100 batches: 0.6647247023809524\n",
      "Average correctly classified images till 2200 batches: 0.6643892045454546\n",
      "Average correctly classified images till 2300 batches: 0.6642866847826088\n",
      "Average correctly classified images till 2400 batches: 0.6645638020833333\n",
      "Average correctly classified images till 2500 batches: 0.66463125\n",
      "Average correctly classified images till 2600 batches: 0.6646935096153846\n",
      "Average correctly classified images till 2700 batches: 0.6649826388888889\n",
      "Average correctly classified images till 2800 batches: 0.6652399553571429\n",
      "Average correctly classified images till 2900 batches: 0.6653933189655172\n",
      "Average correctly classified images till 3000 batches: 0.665484375\n",
      "Average correctly classified images till 3100 batches: 0.6655745967741935\n",
      "Average correctly classified images till 3200 batches: 0.66548828125\n",
      "Average correctly classified images till 3300 batches: 0.665435606060606\n",
      "Epoch: 6, Epoch_Accuracy: 0.67, Epoch_loss: 0.6126\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6892, Best Accuracy: 0.6892\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.6704687500000001\n",
      "Average correctly classified images till 200 batches: 0.673671875\n",
      "Average correctly classified images till 300 batches: 0.669375\n",
      "Average correctly classified images till 400 batches: 0.6689453125\n",
      "Average correctly classified images till 500 batches: 0.6669375\n",
      "Average correctly classified images till 600 batches: 0.6666666666666667\n",
      "Average correctly classified images till 700 batches: 0.6674330357142857\n",
      "Average correctly classified images till 800 batches: 0.667890625\n",
      "Average correctly classified images till 900 batches: 0.6689236111111111\n",
      "Average correctly classified images till 1000 batches: 0.669859375\n",
      "Average correctly classified images till 1100 batches: 0.6705113636363637\n",
      "Average correctly classified images till 1200 batches: 0.6705078125\n",
      "Average correctly classified images till 1300 batches: 0.6705048076923077\n",
      "Average correctly classified images till 1400 batches: 0.6703125\n",
      "Average correctly classified images till 1500 batches: 0.6707916666666667\n",
      "Average correctly classified images till 1600 batches: 0.6719238281250001\n",
      "Average correctly classified images till 1700 batches: 0.6722058823529411\n",
      "Average correctly classified images till 1800 batches: 0.6723611111111111\n",
      "Average correctly classified images till 1900 batches: 0.6721052631578948\n",
      "Average correctly classified images till 2000 batches: 0.67240625\n",
      "Average correctly classified images till 2100 batches: 0.6725595238095238\n",
      "Average correctly classified images till 2200 batches: 0.6726846590909091\n",
      "Average correctly classified images till 2300 batches: 0.6727581521739131\n",
      "Average correctly classified images till 2400 batches: 0.6726106770833333\n",
      "Average correctly classified images till 2500 batches: 0.6727125\n",
      "Average correctly classified images till 2600 batches: 0.6727283653846153\n",
      "Average correctly classified images till 2700 batches: 0.6725925925925925\n",
      "Average correctly classified images till 2800 batches: 0.6729854910714286\n",
      "Average correctly classified images till 2900 batches: 0.6731519396551724\n",
      "Average correctly classified images till 3000 batches: 0.6732239583333333\n",
      "Average correctly classified images till 3100 batches: 0.6734677419354839\n",
      "Average correctly classified images till 3200 batches: 0.673583984375\n",
      "Average correctly classified images till 3300 batches: 0.6736221590909091\n",
      "Epoch: 7, Epoch_Accuracy: 0.67, Epoch_loss: 0.6044\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.6980, Best Accuracy: 0.6980\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.6853125\n",
      "Average correctly classified images till 200 batches: 0.6802343750000001\n",
      "Average correctly classified images till 300 batches: 0.6797395833333334\n",
      "Average correctly classified images till 400 batches: 0.6786328125\n",
      "Average correctly classified images till 500 batches: 0.67721875\n",
      "Average correctly classified images till 600 batches: 0.675234375\n",
      "Average correctly classified images till 700 batches: 0.675625\n",
      "Average correctly classified images till 800 batches: 0.6750976562500001\n",
      "Average correctly classified images till 900 batches: 0.6753819444444444\n",
      "Average correctly classified images till 1000 batches: 0.67515625\n",
      "Average correctly classified images till 1100 batches: 0.6749005681818182\n",
      "Average correctly classified images till 1200 batches: 0.6755859375000001\n",
      "Average correctly classified images till 1300 batches: 0.6757451923076923\n",
      "Average correctly classified images till 1400 batches: 0.6763839285714286\n",
      "Average correctly classified images till 1500 batches: 0.6768229166666666\n",
      "Average correctly classified images till 1600 batches: 0.67669921875\n",
      "Average correctly classified images till 1700 batches: 0.6772794117647059\n",
      "Average correctly classified images till 1800 batches: 0.6771527777777778\n",
      "Average correctly classified images till 1900 batches: 0.6775822368421053\n",
      "Average correctly classified images till 2000 batches: 0.677390625\n",
      "Average correctly classified images till 2100 batches: 0.6775818452380953\n",
      "Average correctly classified images till 2200 batches: 0.6775355113636363\n",
      "Average correctly classified images till 2300 batches: 0.6771739130434783\n",
      "Average correctly classified images till 2400 batches: 0.6767903645833334\n",
      "Average correctly classified images till 2500 batches: 0.67711875\n",
      "Average correctly classified images till 2600 batches: 0.6770192307692308\n",
      "Average correctly classified images till 2700 batches: 0.6771180555555555\n",
      "Average correctly classified images till 2800 batches: 0.6771875\n",
      "Average correctly classified images till 2900 batches: 0.6772575431034482\n",
      "Average correctly classified images till 3000 batches: 0.6775104166666667\n",
      "Average correctly classified images till 3100 batches: 0.6773840725806451\n",
      "Average correctly classified images till 3200 batches: 0.6773046875000001\n",
      "Average correctly classified images till 3300 batches: 0.6773248106060606\n",
      "Epoch: 8, Epoch_Accuracy: 0.68, Epoch_loss: 0.5999\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.7012, Best Accuracy: 0.7012\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.6878125\n",
      "Average correctly classified images till 200 batches: 0.6853125\n",
      "Average correctly classified images till 300 batches: 0.6840104166666667\n",
      "Average correctly classified images till 400 batches: 0.6825\n",
      "Average correctly classified images till 500 batches: 0.68446875\n",
      "Average correctly classified images till 600 batches: 0.6824479166666667\n",
      "Average correctly classified images till 700 batches: 0.6827901785714285\n",
      "Average correctly classified images till 800 batches: 0.68375\n",
      "Average correctly classified images till 900 batches: 0.6833159722222222\n",
      "Average correctly classified images till 1000 batches: 0.68290625\n",
      "Average correctly classified images till 1100 batches: 0.6833380681818182\n",
      "Average correctly classified images till 1200 batches: 0.6835546875\n",
      "Average correctly classified images till 1300 batches: 0.683545673076923\n",
      "Average correctly classified images till 1400 batches: 0.6838392857142858\n",
      "Average correctly classified images till 1500 batches: 0.6836770833333333\n",
      "Average correctly classified images till 1600 batches: 0.68361328125\n",
      "Average correctly classified images till 1700 batches: 0.6835294117647058\n",
      "Average correctly classified images till 1800 batches: 0.683046875\n",
      "Average correctly classified images till 2200 batches: 0.6818678977272727\n",
      "Average correctly classified images till 2300 batches: 0.6822554347826087\n",
      "Average correctly classified images till 2400 batches: 0.68224609375\n",
      "Average correctly classified images till 2500 batches: 0.6821\n",
      "Average correctly classified images till 2600 batches: 0.6822716346153846\n",
      "Average correctly classified images till 2700 batches: 0.6822685185185184\n",
      "Average correctly classified images till 2800 batches: 0.6822935267857143\n",
      "Average correctly classified images till 2900 batches: 0.6822521551724138\n",
      "Average correctly classified images till 3000 batches: 0.6821614583333333\n",
      "Average correctly classified images till 3100 batches: 0.6820413306451613\n",
      "Average correctly classified images till 3200 batches: 0.68203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctly classified images till 3300 batches: 0.6820785984848485\n",
      "Epoch: 9, Epoch_Accuracy: 0.68, Epoch_loss: 0.5964\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.7028, Best Accuracy: 0.7028\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.68375\n",
      "Average correctly classified images till 200 batches: 0.681484375\n",
      "Average correctly classified images till 300 batches: 0.6764062500000001\n",
      "Average correctly classified images till 400 batches: 0.678828125\n",
      "Average correctly classified images till 500 batches: 0.6800625\n",
      "Average correctly classified images till 600 batches: 0.6807031250000001\n",
      "Average correctly classified images till 700 batches: 0.6808035714285714\n",
      "Average correctly classified images till 800 batches: 0.681875\n",
      "Average correctly classified images till 900 batches: 0.6822222222222222\n",
      "Average correctly classified images till 1000 batches: 0.6823281250000001\n",
      "Average correctly classified images till 1100 batches: 0.68234375\n",
      "Average correctly classified images till 1200 batches: 0.6828645833333333\n",
      "Average correctly classified images till 1300 batches: 0.6828725961538461\n",
      "Average correctly classified images till 1400 batches: 0.6838169642857143\n",
      "Average correctly classified images till 1500 batches: 0.6835625\n",
      "Average correctly classified images till 1600 batches: 0.683486328125\n",
      "Average correctly classified images till 1700 batches: 0.6838419117647058\n",
      "Average correctly classified images till 1800 batches: 0.6839670138888889\n",
      "Average correctly classified images till 1900 batches: 0.6837746710526316\n",
      "Average correctly classified images till 2000 batches: 0.6839921875\n",
      "Average correctly classified images till 2100 batches: 0.6842708333333334\n",
      "Average correctly classified images till 2200 batches: 0.6835227272727272\n",
      "Average correctly classified images till 2300 batches: 0.6833016304347826\n",
      "Average correctly classified images till 2400 batches: 0.6833723958333334\n",
      "Average correctly classified images till 2500 batches: 0.6833312500000001\n",
      "Average correctly classified images till 2600 batches: 0.6832091346153846\n",
      "Average correctly classified images till 2700 batches: 0.6835706018518518\n",
      "Average correctly classified images till 2800 batches: 0.6834709821428572\n",
      "Average correctly classified images till 2900 batches: 0.6831411637931034\n",
      "Average correctly classified images till 3000 batches: 0.6833697916666667\n",
      "Average correctly classified images till 3100 batches: 0.6833618951612903\n",
      "Average correctly classified images till 3200 batches: 0.683251953125\n",
      "Average correctly classified images till 3300 batches: 0.6833001893939394\n",
      "Epoch: 10, Epoch_Accuracy: 0.68, Epoch_loss: 0.5940\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.7047, Best Accuracy: 0.7047\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.6996875\n",
      "Average correctly classified images till 200 batches: 0.68953125\n",
      "Average correctly classified images till 300 batches: 0.69015625\n",
      "Average correctly classified images till 400 batches: 0.6887890625\n",
      "Average correctly classified images till 500 batches: 0.6870937500000001\n",
      "Average correctly classified images till 600 batches: 0.6864583333333334\n",
      "Average correctly classified images till 700 batches: 0.6850446428571428\n",
      "Average correctly classified images till 800 batches: 0.6848632812500001\n",
      "Average correctly classified images till 900 batches: 0.6841666666666667\n",
      "Average correctly classified images till 1000 batches: 0.683953125\n",
      "Average correctly classified images till 1100 batches: 0.6835227272727272\n",
      "Average correctly classified images till 1200 batches: 0.6833203125\n",
      "Average correctly classified images till 1300 batches: 0.683545673076923\n",
      "Average correctly classified images till 1400 batches: 0.6839285714285714\n",
      "Average correctly classified images till 1500 batches: 0.6839062499999999\n",
      "Average correctly classified images till 1600 batches: 0.6838671875\n",
      "Average correctly classified images till 1700 batches: 0.6837959558823529\n",
      "Average correctly classified images till 1800 batches: 0.6839149305555555\n",
      "Average correctly classified images till 1900 batches: 0.6836842105263158\n",
      "Average correctly classified images till 2000 batches: 0.6837421875\n",
      "Average correctly classified images till 2100 batches: 0.68359375\n",
      "Average correctly classified images till 2200 batches: 0.6836363636363636\n",
      "Average correctly classified images till 2300 batches: 0.6837567934782609\n",
      "Average correctly classified images till 2400 batches: 0.6836067708333334\n",
      "Average correctly classified images till 2500 batches: 0.683925\n",
      "Average correctly classified images till 2600 batches: 0.6840745192307692\n",
      "Average correctly classified images till 2700 batches: 0.6843634259259259\n",
      "Average correctly classified images till 2800 batches: 0.6838727678571429\n",
      "Average correctly classified images till 2900 batches: 0.6839224137931034\n",
      "Average correctly classified images till 3000 batches: 0.6840625\n",
      "Average correctly classified images till 3100 batches: 0.6842792338709678\n",
      "Average correctly classified images till 3200 batches: 0.684248046875\n",
      "Average correctly classified images till 3300 batches: 0.6842234848484848\n",
      "Epoch: 11, Epoch_Accuracy: 0.68, Epoch_loss: 0.5914\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.7076, Best Accuracy: 0.7076\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.70703125\n",
      "Average correctly classified images till 200 batches: 0.69578125\n",
      "Average correctly classified images till 300 batches: 0.6939583333333333\n",
      "Average correctly classified images till 400 batches: 0.694765625\n",
      "Average correctly classified images till 500 batches: 0.69271875\n",
      "Average correctly classified images till 600 batches: 0.6910937500000001\n",
      "Average correctly classified images till 700 batches: 0.6908035714285714\n",
      "Average correctly classified images till 800 batches: 0.688984375\n",
      "Average correctly classified images till 900 batches: 0.6887673611111111\n",
      "Average correctly classified images till 1000 batches: 0.6890000000000001\n",
      "Average correctly classified images till 1100 batches: 0.6886505681818181\n",
      "Average correctly classified images till 1200 batches: 0.6880729166666667\n",
      "Average correctly classified images till 1300 batches: 0.6872716346153847\n",
      "Average correctly classified images till 1400 batches: 0.6869308035714285\n",
      "Average correctly classified images till 1500 batches: 0.6866145833333334\n",
      "Average correctly classified images till 1600 batches: 0.686181640625\n",
      "Average correctly classified images till 1700 batches: 0.6864522058823529\n",
      "Average correctly classified images till 1800 batches: 0.6865104166666667\n",
      "Average correctly classified images till 1900 batches: 0.6863815789473684\n",
      "Average correctly classified images till 2000 batches: 0.6861406250000001\n",
      "Average correctly classified images till 2100 batches: 0.6860044642857143\n",
      "Average correctly classified images till 2200 batches: 0.686221590909091\n",
      "Average correctly classified images till 2300 batches: 0.6865964673913044\n",
      "Average correctly classified images till 2400 batches: 0.68673828125\n",
      "Average correctly classified images till 2500 batches: 0.68654375\n",
      "Average correctly classified images till 2600 batches: 0.6864182692307692\n",
      "Average correctly classified images till 2700 batches: 0.6865277777777777\n",
      "Average correctly classified images till 2800 batches: 0.6865290178571428\n",
      "Average correctly classified images till 2900 batches: 0.6866756465517241\n",
      "Average correctly classified images till 3000 batches: 0.6865729166666666\n",
      "Average correctly classified images till 3100 batches: 0.6865423387096774\n",
      "Average correctly classified images till 3200 batches: 0.6865380859375\n",
      "Average correctly classified images till 3300 batches: 0.6866808712121212\n",
      "Epoch: 12, Epoch_Accuracy: 0.69, Epoch_loss: 0.5905\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.7090, Best Accuracy: 0.7090\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.69375\n",
      "Average correctly classified images till 200 batches: 0.6871875000000001\n",
      "Average correctly classified images till 300 batches: 0.6865625000000001\n",
      "Average correctly classified images till 400 batches: 0.6837109375\n",
      "Average correctly classified images till 500 batches: 0.68459375\n",
      "Average correctly classified images till 600 batches: 0.6846614583333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctly classified images till 700 batches: 0.68515625\n",
      "Average correctly classified images till 800 batches: 0.6862890625\n",
      "Average correctly classified images till 900 batches: 0.6856423611111111\n",
      "Average correctly classified images till 1000 batches: 0.68503125\n",
      "Average correctly classified images till 1100 batches: 0.6856392045454546\n",
      "Average correctly classified images till 1200 batches: 0.6855989583333334\n",
      "Average correctly classified images till 1300 batches: 0.685264423076923\n",
      "Average correctly classified images till 1400 batches: 0.6859709821428571\n",
      "Average correctly classified images till 1500 batches: 0.6862291666666667\n",
      "Average correctly classified images till 1600 batches: 0.68640625\n",
      "Average correctly classified images till 1700 batches: 0.6867647058823528\n",
      "Average correctly classified images till 1800 batches: 0.6866493055555556\n",
      "Average correctly classified images till 1900 batches: 0.6865542763157895\n",
      "Average correctly classified images till 2000 batches: 0.6862734375\n",
      "Average correctly classified images till 2100 batches: 0.686108630952381\n",
      "Average correctly classified images till 2200 batches: 0.6863423295454546\n",
      "Average correctly classified images till 2300 batches: 0.6864538043478261\n",
      "Average correctly classified images till 2400 batches: 0.6866666666666668\n",
      "Average correctly classified images till 2500 batches: 0.68691875\n",
      "Average correctly classified images till 2600 batches: 0.6865745192307692\n",
      "Average correctly classified images till 2700 batches: 0.6869097222222222\n",
      "Average correctly classified images till 2800 batches: 0.6868024553571429\n",
      "Average correctly classified images till 2900 batches: 0.6867780172413792\n",
      "Average correctly classified images till 3000 batches: 0.687078125\n",
      "Average correctly classified images till 3100 batches: 0.6869909274193549\n",
      "Average correctly classified images till 3200 batches: 0.6868798828125\n",
      "Average correctly classified images till 3300 batches: 0.6866619318181818\n",
      "Epoch: 13, Epoch_Accuracy: 0.69, Epoch_loss: 0.5895\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.7104, Best Accuracy: 0.7104\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.7039062500000001\n",
      "Average correctly classified images till 200 batches: 0.698125\n",
      "Average correctly classified images till 300 batches: 0.69734375\n",
      "Average correctly classified images till 400 batches: 0.693828125\n",
      "Average correctly classified images till 500 batches: 0.69428125\n",
      "Average correctly classified images till 600 batches: 0.6926302083333333\n",
      "Average correctly classified images till 700 batches: 0.6928794642857142\n",
      "Average correctly classified images till 800 batches: 0.69263671875\n",
      "Average correctly classified images till 900 batches: 0.6922222222222222\n",
      "Average correctly classified images till 1000 batches: 0.69175\n",
      "Average correctly classified images till 1100 batches: 0.69203125\n",
      "Average correctly classified images till 1200 batches: 0.6922786458333334\n",
      "Average correctly classified images till 1300 batches: 0.6920432692307692\n",
      "Average correctly classified images till 1400 batches: 0.6917522321428572\n",
      "Average correctly classified images till 1500 batches: 0.6915104166666667\n",
      "Average correctly classified images till 1600 batches: 0.69134765625\n",
      "Average correctly classified images till 1700 batches: 0.6911856617647059\n",
      "Average correctly classified images till 1800 batches: 0.6912586805555555\n",
      "Average correctly classified images till 1900 batches: 0.6912335526315789\n",
      "Average correctly classified images till 2000 batches: 0.6914296875\n",
      "Average correctly classified images till 2100 batches: 0.6915178571428572\n",
      "Average correctly classified images till 2200 batches: 0.6906960227272727\n",
      "Average correctly classified images till 2300 batches: 0.6903600543478261\n",
      "Average correctly classified images till 2400 batches: 0.6902473958333334\n",
      "Average correctly classified images till 2500 batches: 0.6902312500000001\n",
      "Average correctly classified images till 2600 batches: 0.6902764423076924\n",
      "Average correctly classified images till 2700 batches: 0.6902256944444444\n",
      "Average correctly classified images till 2800 batches: 0.6902790178571429\n",
      "Average correctly classified images till 2900 batches: 0.6904956896551724\n",
      "Average correctly classified images till 3000 batches: 0.6903177083333333\n",
      "Average correctly classified images till 3100 batches: 0.6903276209677419\n",
      "Average correctly classified images till 3200 batches: 0.6901953125\n",
      "Average correctly classified images till 3300 batches: 0.6900852272727273\n",
      "Epoch: 14, Epoch_Accuracy: 0.69, Epoch_loss: 0.5860\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.7118, Best Accuracy: 0.7118\n"
     ]
    }
   ],
   "source": [
    "train(model_conv, dset_loader_l1, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for the second hierarchy after removing the last linear layer and adding another linear layer of 6 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model_conv.parameters():\n",
    "    params.requires_grad=False\n",
    "    \n",
    "model_conv.fc = nn.Sequential(*list(model_conv.fc.children())[:-4],\n",
    "                               nn.BatchNorm1d(50),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Dropout(p = 0.5),\n",
    "                               nn.Linear(50,7))\n",
    "\n",
    "# print (model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=256, out_features=50, bias=True)\n",
       "    (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=50, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_conv.load_state_dict(torch.load(\"Resnet50_Transfer_Learning.model\"))\n",
    "model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.12953125000000001\n",
      "Average correctly classified images till 200 batches: 0.135625\n",
      "Average correctly classified images till 300 batches: 0.13239583333333335\n",
      "Average correctly classified images till 400 batches: 0.13203125\n",
      "Average correctly classified images till 500 batches: 0.133125\n",
      "Average correctly classified images till 600 batches: 0.133671875\n",
      "Average correctly classified images till 700 batches: 0.13334821428571428\n",
      "Average correctly classified images till 800 batches: 0.13322265625000002\n",
      "Average correctly classified images till 900 batches: 0.13211805555555556\n",
      "Average correctly classified images till 1000 batches: 0.13215625\n",
      "Average correctly classified images till 1100 batches: 0.13241477272727273\n",
      "Average correctly classified images till 1200 batches: 0.1322265625\n",
      "Average correctly classified images till 1300 batches: 0.13243990384615384\n",
      "Average correctly classified images till 1400 batches: 0.13247767857142856\n",
      "Average correctly classified images till 1500 batches: 0.13245833333333332\n",
      "Average correctly classified images till 1600 batches: 0.132392578125\n",
      "Average correctly classified images till 1700 batches: 0.13224264705882352\n",
      "Average correctly classified images till 1800 batches: 0.13201388888888888\n",
      "Average correctly classified images till 1900 batches: 0.1318996710526316\n",
      "Average correctly classified images till 2000 batches: 0.131828125\n",
      "Average correctly classified images till 2100 batches: 0.13192708333333333\n",
      "Average correctly classified images till 2200 batches: 0.13189630681818182\n",
      "Average correctly classified images till 2300 batches: 0.13211956521739132\n",
      "Average correctly classified images till 2400 batches: 0.13221354166666668\n",
      "Average correctly classified images till 2500 batches: 0.1323125\n",
      "Average correctly classified images till 2600 batches: 0.1321875\n",
      "Average correctly classified images till 2700 batches: 0.1321412037037037\n",
      "Average correctly classified images till 2800 batches: 0.13200892857142857\n",
      "Average correctly classified images till 2900 batches: 0.1320581896551724\n",
      "Average correctly classified images till 3000 batches: 0.131984375\n",
      "Average correctly classified images till 3100 batches: 0.1319304435483871\n",
      "Average correctly classified images till 3200 batches: 0.1318115234375\n",
      "Average correctly classified images till 3300 batches: 0.13214488636363636\n",
      "Epoch: 0, Epoch_Accuracy: 0.13, Epoch_loss: 2.0458\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.0965, Best Accuracy: 0.0965\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.14421875\n",
      "Average correctly classified images till 200 batches: 0.13734375000000001\n",
      "Average correctly classified images till 300 batches: 0.13458333333333333\n",
      "Average correctly classified images till 400 batches: 0.1325\n",
      "Average correctly classified images till 500 batches: 0.1326875\n",
      "Average correctly classified images till 600 batches: 0.13208333333333333\n",
      "Average correctly classified images till 700 batches: 0.13133928571428571\n",
      "Average correctly classified images till 800 batches: 0.13203125\n",
      "Average correctly classified images till 900 batches: 0.13272569444444443\n",
      "Average correctly classified images till 1000 batches: 0.13265625\n",
      "Average correctly classified images till 1100 batches: 0.13257102272727272\n",
      "Average correctly classified images till 1200 batches: 0.13204427083333334\n",
      "Average correctly classified images till 1300 batches: 0.1322716346153846\n",
      "Average correctly classified images till 1400 batches: 0.13220982142857143\n",
      "Average correctly classified images till 1500 batches: 0.13239583333333332\n",
      "Average correctly classified images till 1600 batches: 0.13228515625\n",
      "Average correctly classified images till 1700 batches: 0.13237132352941175\n",
      "Average correctly classified images till 1800 batches: 0.1325434027777778\n",
      "Average correctly classified images till 1900 batches: 0.13265625\n",
      "Average correctly classified images till 2000 batches: 0.1328125\n",
      "Average correctly classified images till 2100 batches: 0.1330059523809524\n",
      "Average correctly classified images till 2200 batches: 0.13274857954545455\n",
      "Average correctly classified images till 2300 batches: 0.1326358695652174\n",
      "Average correctly classified images till 2400 batches: 0.13283854166666667\n",
      "Average correctly classified images till 2500 batches: 0.1326875\n",
      "Average correctly classified images till 2600 batches: 0.13265625\n",
      "Average correctly classified images till 2700 batches: 0.1327546296296296\n",
      "Average correctly classified images till 2800 batches: 0.13286830357142856\n",
      "Average correctly classified images till 2900 batches: 0.13288254310344827\n",
      "Average correctly classified images till 3000 batches: 0.13275520833333332\n",
      "Average correctly classified images till 3100 batches: 0.1328578629032258\n",
      "Average correctly classified images till 3200 batches: 0.1328955078125\n",
      "Average correctly classified images till 3300 batches: 0.13303977272727271\n",
      "Epoch: 1, Epoch_Accuracy: 0.13, Epoch_loss: 2.0455\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.1003, Best Accuracy: 0.1003\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.1265625\n",
      "Average correctly classified images till 200 batches: 0.12859375\n",
      "Average correctly classified images till 300 batches: 0.13072916666666667\n",
      "Average correctly classified images till 400 batches: 0.1319921875\n",
      "Average correctly classified images till 500 batches: 0.1326875\n",
      "Average correctly classified images till 600 batches: 0.1333072916666667\n",
      "Average correctly classified images till 700 batches: 0.13310267857142857\n",
      "Average correctly classified images till 800 batches: 0.1328125\n",
      "Average correctly classified images till 900 batches: 0.13371527777777778\n",
      "Average correctly classified images till 1000 batches: 0.13340625\n",
      "Average correctly classified images till 1100 batches: 0.13353693181818183\n",
      "Average correctly classified images till 1200 batches: 0.13361979166666668\n",
      "Average correctly classified images till 1300 batches: 0.1334735576923077\n",
      "Average correctly classified images till 1400 batches: 0.133203125\n",
      "Average correctly classified images till 1500 batches: 0.13329166666666667\n",
      "Average correctly classified images till 1600 batches: 0.132861328125\n",
      "Average correctly classified images till 1700 batches: 0.13283088235294116\n",
      "Average correctly classified images till 1800 batches: 0.13310763888888888\n",
      "Average correctly classified images till 1900 batches: 0.1333141447368421\n",
      "Average correctly classified images till 2000 batches: 0.13309375\n",
      "Average correctly classified images till 2100 batches: 0.13335565476190475\n",
      "Average correctly classified images till 2200 batches: 0.13350852272727273\n",
      "Average correctly classified images till 2300 batches: 0.13336277173913044\n",
      "Average correctly classified images till 2400 batches: 0.13322916666666668\n",
      "Average correctly classified images till 2500 batches: 0.13330625000000002\n",
      "Average correctly classified images till 2600 batches: 0.13317908653846153\n",
      "Average correctly classified images till 2700 batches: 0.1333912037037037\n",
      "Average correctly classified images till 2800 batches: 0.13347098214285713\n",
      "Average correctly classified images till 2900 batches: 0.13341594827586206\n",
      "Average correctly classified images till 3300 batches: 0.13319128787878787\n",
      "Epoch: 2, Epoch_Accuracy: 0.13, Epoch_loss: 2.0463\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.1005, Best Accuracy: 0.1005\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.13546875\n",
      "Average correctly classified images till 200 batches: 0.1309375\n",
      "Average correctly classified images till 300 batches: 0.13119791666666666\n",
      "Average correctly classified images till 400 batches: 0.1337890625\n",
      "Average correctly classified images till 500 batches: 0.13446875\n",
      "Average correctly classified images till 600 batches: 0.13296875\n",
      "Average correctly classified images till 700 batches: 0.13258928571428572\n",
      "Average correctly classified images till 800 batches: 0.133203125\n",
      "Average correctly classified images till 900 batches: 0.13307291666666668\n",
      "Average correctly classified images till 1000 batches: 0.133765625\n",
      "Average correctly classified images till 1100 batches: 0.13372159090909091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctly classified images till 1200 batches: 0.1329296875\n",
      "Average correctly classified images till 1300 batches: 0.13274038461538462\n",
      "Average correctly classified images till 1400 batches: 0.132890625\n",
      "Average correctly classified images till 1500 batches: 0.1330625\n",
      "Average correctly classified images till 1600 batches: 0.13330078125\n",
      "Average correctly classified images till 1700 batches: 0.13323529411764704\n",
      "Average correctly classified images till 1800 batches: 0.13278645833333333\n",
      "Average correctly classified images till 1900 batches: 0.13289473684210526\n",
      "Average correctly classified images till 2000 batches: 0.1331328125\n",
      "Average correctly classified images till 2100 batches: 0.1332142857142857\n",
      "Average correctly classified images till 2200 batches: 0.13319602272727274\n",
      "Average correctly classified images till 2300 batches: 0.1331521739130435\n",
      "Average correctly classified images till 2400 batches: 0.13341145833333334\n",
      "Average correctly classified images till 2500 batches: 0.13331875\n",
      "Average correctly classified images till 2600 batches: 0.1335576923076923\n",
      "Average correctly classified images till 2700 batches: 0.13331597222222222\n",
      "Average correctly classified images till 2800 batches: 0.13342075892857141\n",
      "Average correctly classified images till 2900 batches: 0.1333405172413793\n",
      "Average correctly classified images till 3000 batches: 0.1333125\n",
      "Average correctly classified images till 3100 batches: 0.13316532258064517\n",
      "Average correctly classified images till 3200 batches: 0.133095703125\n",
      "Average correctly classified images till 3300 batches: 0.13310606060606062\n",
      "Epoch: 3, Epoch_Accuracy: 0.13, Epoch_loss: 2.0470\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.1010, Best Accuracy: 0.1010\n",
      "Average correctly classified images till 0 batches: inf\n",
      "Average correctly classified images till 100 batches: 0.13375\n",
      "Average correctly classified images till 200 batches: 0.133125\n",
      "Average correctly classified images till 300 batches: 0.1379166666666667\n",
      "Average correctly classified images till 400 batches: 0.137109375\n",
      "Average correctly classified images till 500 batches: 0.13746875\n",
      "Average correctly classified images till 600 batches: 0.13716145833333335\n",
      "Average correctly classified images till 700 batches: 0.13707589285714286\n",
      "Average correctly classified images till 800 batches: 0.13705078125\n",
      "Average correctly classified images till 900 batches: 0.1371875\n",
      "Average correctly classified images till 1000 batches: 0.1375625\n",
      "Average correctly classified images till 1100 batches: 0.13757102272727273\n",
      "Average correctly classified images till 1200 batches: 0.13768229166666668\n",
      "Average correctly classified images till 1300 batches: 0.13709134615384616\n",
      "Average correctly classified images till 1400 batches: 0.136875\n",
      "Average correctly classified images till 1500 batches: 0.13729166666666667\n",
      "Average correctly classified images till 1600 batches: 0.137138671875\n",
      "Average correctly classified images till 1700 batches: 0.13777573529411763\n",
      "Average correctly classified images till 1800 batches: 0.13784722222222223\n",
      "Average correctly classified images till 1900 batches: 0.1377878289473684\n",
      "Average correctly classified images till 2000 batches: 0.138109375\n",
      "Average correctly classified images till 2100 batches: 0.1382514880952381\n",
      "Average correctly classified images till 2200 batches: 0.13828835227272726\n",
      "Average correctly classified images till 2300 batches: 0.1385461956521739\n",
      "Average correctly classified images till 2400 batches: 0.13864583333333333\n",
      "Average correctly classified images till 2500 batches: 0.13883125000000002\n",
      "Average correctly classified images till 2600 batches: 0.13887620192307693\n",
      "Average correctly classified images till 2700 batches: 0.13913194444444443\n",
      "Average correctly classified images till 2800 batches: 0.13934151785714285\n",
      "Average correctly classified images till 2900 batches: 0.13963362068965515\n",
      "Average correctly classified images till 3000 batches: 0.13983854166666665\n",
      "Average correctly classified images till 3100 batches: 0.13981854838709679\n",
      "Average correctly classified images till 3200 batches: 0.1400537109375\n",
      "Average correctly classified images till 3300 batches: 0.14019886363636364\n",
      "Epoch: 4, Epoch_Accuracy: 0.14, Epoch_loss: 2.0413\n",
      "Chekcpoint updated\n",
      "Test Accuracy: 0.1265, Best Accuracy: 0.1265\n"
     ]
    }
   ],
   "source": [
    "train(model_conv, dset_loader_l2, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
